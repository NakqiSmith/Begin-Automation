{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Creation and Automated Reporting Instruction Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Application Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab and Open Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below does exactly what I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Importation\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Loading Necessary Workbooks\n",
    "wb1 = load_workbook (\"StaffPerformanceOverviewCR06-23-23 test copy.xlsx\")\n",
    "wb2 = load_workbook(\"StaffPerformanceOverviewNH06-23-23 test copy.xlsx\")\n",
    "ws1 = wb1.active\n",
    "ws2 = wb2.active\n",
    "\n",
    "#Appending Data To One Workbook\n",
    "for row in ws2.iter_rows(min_row=2, values_only=True): \n",
    "    ws1.append(row)\n",
    "\n",
    "wb1.save(\"StaffPerformanceOverviewtest-06-23 test copy.xlsx\")\n",
    "\n",
    "#reload new workbook that was just saved\n",
    "wb = load_workbook(\"StaffPerformanceOverviewtest-06-23 test copy.xlsx\")\n",
    "ws = wb.active\n",
    "\n",
    "#Remove Row to consolidate data\n",
    "start_row = 12\n",
    "num_rows_to_remove = 1\n",
    "ws.delete_rows(start_row, num_rows_to_remove)\n",
    "\n",
    "# Define the column letter you want to update (e.g., column A)\n",
    "column_letter = 'E'\n",
    "\n",
    "# Define the value to be replaced and its corresponding replacement\n",
    "old = \"NA\"\n",
    "new = \"0\"\n",
    "\n",
    "# Get the column index from the column letter\n",
    "column_index = ord(column_letter) - ord('A') + 1\n",
    "\n",
    "# Loop through the cells in the selected column and replace the old value with the new value\n",
    "for row in ws.iter_rows(min_row=3, min_col=column_index, max_col=column_index):\n",
    "    cell = row[0]\n",
    "    if cell.value == old:\n",
    "        cell.value = new\n",
    "\n",
    "from openpyxl.styles import NamedStyle\n",
    "\n",
    "# Create named style for the whole number format\n",
    "whole_number_style = NamedStyle(name=\"whole_number\", number_format=\"0\")\n",
    "\n",
    "# Columns that need to be formatted as a whole number (example: columns A, B, and D)\n",
    "columns_to_format = ['B', 'C', 'D']  # Replace with the letters of the columns you want to format\n",
    "\n",
    "# Apply the named style to each cell in the selected columns\n",
    "for column_letter in columns_to_format:\n",
    "    for cell in ws[column_letter]:\n",
    "        cell.style = whole_number_style\n",
    "\n",
    "Decimal_Number_Style = NamedStyle(name=\"decimal\", number_format=\"#,##0.00\")\n",
    "\n",
    "column_letter = 'E'\n",
    "for cell in ws[column_letter]:\n",
    "    cell.style = Decimal_Number_Style\n",
    "\n",
    "# Create named style for the whole number format\n",
    "currency_style = NamedStyle(name=\"currency\", number_format='\"$\"#,##0.00')\n",
    "\n",
    "# Columns that need to be formatted as a whole number (example: columns A, B, and D)\n",
    "columns_to_format = ['F', 'G', 'H','I','J','K','L','M','N','O']  # Replace with the letters of the columns you want to format\n",
    "\n",
    "# Apply the named style to each cell in the selected columns\n",
    "for column_letter in columns_to_format:\n",
    "    for cell in ws[column_letter]:\n",
    "        cell.style = currency_style\n",
    "\n",
    "wb.save(\"StaffPerformanceOverviewtest-06-23 test copy.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below does exactly what i want right after the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Data12, dtype: float64)\n",
      "Series([], Name: Data12, dtype: float64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData12\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData12_loc1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData12_loc2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     66\u001b[0m \u001b[39m# Calculate the average for Data4 to Data6 columns\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData4\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (consolidated_data_both_locations[\u001b[39m'\u001b[39;49m\u001b[39mData4_loc1\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m consolidated_data_both_locations[\u001b[39m'\u001b[39;49m\u001b[39mData4_loc2\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     68\u001b[0m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData13\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData13_loc1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData13_loc2\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     69\u001b[0m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData14\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData14_loc1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m consolidated_data_both_locations[\u001b[39m'\u001b[39m\u001b[39mData14_loc2\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__add__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__add__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39m    moose     3.0     NaN\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49madd)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:6112\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   6111\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 6112\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1350\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:178\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    179\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:116\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 116\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[0;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load the existing Excel workbook\n",
    "wb = load_workbook(\"StaffPerformanceOverviewtest-06-23 test copy.xlsx\")\n",
    "\n",
    "# Select the worksheet you want to update (assuming it's the first sheet)\n",
    "ws = wb.active\n",
    "\n",
    "# Read the data from the worksheet into a Pandas DataFrame\n",
    "data_range_location1 = ws['A3:O11']  # Assuming data for location 1 is in columns A to K starting from row 2\n",
    "data_location1 = [[cell.value for cell in row] for row in data_range_location1]\n",
    "\n",
    "data_range_location2 = ws['A12:O18']  # Assuming data for location 2 is in columns A to K starting from row 2\n",
    "data_location2 = [[cell.value for cell in row] for row in data_range_location2]\n",
    "\n",
    "# Create separate DataFrames for location 1 and location 2\n",
    "df_location1 = pd.DataFrame(data_location1, columns=['EmployeeID', 'Data1', 'Data2', 'Data3', 'Data4', 'Data5', 'Data6', 'Data7', \n",
    "                                                                                            'Data8', 'Data9', 'Data10', 'Data11', 'Data12', 'Data13', 'Data14'])\n",
    "df_location2 = pd.DataFrame(data_location2, columns=['EmployeeID', 'Data1', 'Data2', 'Data3', 'Data4', 'Data5', 'Data6', 'Data7',\n",
    "                                                                                             'Data8', 'Data9', 'Data10', 'Data11', 'Data12', 'Data13', 'Data14'])\n",
    "\n",
    "# Check for any non-numeric values in 'Data12' columns\n",
    "print(df_location1[df_location1['Data12'].isna()]['Data12'])\n",
    "print(df_location2[df_location2['Data12'].isna()]['Data12'])\n",
    "\n",
    "# Get the union of EmployeeIDs from both data frames\n",
    "all_employee_ids = set(df_location1['EmployeeID']).union(set(df_location2['EmployeeID']))\n",
    "\n",
    "# Create DataFrames with all EmployeeIDs for both locations\n",
    "df_all_location1 = pd.DataFrame({'EmployeeID': list(all_employee_ids)})\n",
    "df_all_location2 = pd.DataFrame({'EmployeeID': list(all_employee_ids)})\n",
    "\n",
    "# Merge the original data with the DataFrames containing all EmployeeIDs (outer merge)\n",
    "merged_location1 = pd.merge(df_all_location1, df_location1, on='EmployeeID', how='left')\n",
    "merged_location2 = pd.merge(df_all_location2, df_location2, on='EmployeeID', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_location1.fillna(0, inplace=True)\n",
    "merged_location2.fillna(0, inplace=True)\n",
    "\n",
    "# Consolidate data based on EmployeeID and calculate the sum for each location\n",
    "consolidated_data_location1 = merged_location1.groupby('EmployeeID', as_index=False).sum()\n",
    "consolidated_data_location2 = merged_location2.groupby('EmployeeID', as_index=False).sum()\n",
    "\n",
    "# Merge the consolidated data for employees working at both locations (outer merge)\n",
    "consolidated_data_both_locations = pd.merge(consolidated_data_location1, consolidated_data_location2, on='EmployeeID', suffixes=('_loc1', '_loc2'), how='outer')\n",
    "\n",
    "# Calculate the final values for the Data1, Data2, Data3 columns (sum for all)\n",
    "consolidated_data_both_locations['Data1'] = consolidated_data_both_locations['Data1_loc1'] + consolidated_data_both_locations['Data1_loc2']\n",
    "consolidated_data_both_locations['Data2'] = consolidated_data_both_locations['Data2_loc1'] + consolidated_data_both_locations['Data2_loc2']\n",
    "consolidated_data_both_locations['Data3'] = consolidated_data_both_locations['Data3_loc1'] + consolidated_data_both_locations['Data3_loc2']\n",
    "consolidated_data_both_locations['Data5'] = consolidated_data_both_locations['Data5_loc1'] + consolidated_data_both_locations['Data7_loc2']\n",
    "consolidated_data_both_locations['Data6'] = consolidated_data_both_locations['Data6_loc1'] + consolidated_data_both_locations['Data8_loc2']\n",
    "consolidated_data_both_locations['Data7'] = consolidated_data_both_locations['Data7_loc1'] + consolidated_data_both_locations['Data7_loc2']\n",
    "consolidated_data_both_locations['Data8'] = consolidated_data_both_locations['Data8_loc1'] + consolidated_data_both_locations['Data8_loc2']\n",
    "consolidated_data_both_locations['Data9'] = consolidated_data_both_locations['Data9_loc1'] + consolidated_data_both_locations['Data9_loc2']\n",
    "consolidated_data_both_locations['Data10'] = consolidated_data_both_locations['Data10_loc1'] + consolidated_data_both_locations['Data10_loc2']\n",
    "consolidated_data_both_locations['Data11'] = consolidated_data_both_locations['Data11_loc1'] + consolidated_data_both_locations['Data11_loc2']\n",
    "consolidated_data_both_locations['Data12'] = consolidated_data_both_locations['Data12_loc1'] + consolidated_data_both_locations['Data12_loc2']\n",
    "\n",
    "# Calculate the average for Data4 to Data6 columns\n",
    "consolidated_data_both_locations['Data4'] = (consolidated_data_both_locations['Data4_loc1'] + consolidated_data_both_locations['Data4_loc2']) / 2\n",
    "consolidated_data_both_locations['Data13'] = (consolidated_data_both_locations['Data13_loc1'] + consolidated_data_both_locations['Data13_loc2']) / 2\n",
    "consolidated_data_both_locations['Data14'] = (consolidated_data_both_locations['Data14_loc1'] + consolidated_data_both_locations['Data14_loc2']) / 2\n",
    "\n",
    "# Remove the unnecessary columns from the consolidated DataFrame\n",
    "consolidated_data_both_locations.drop(columns=[\n",
    "    'Data1_loc1', 'Data1_loc2', 'Data2_loc1', 'Data2_loc2', 'Data3_loc1', 'Data3_loc2',\n",
    "    'Data4_loc1', 'Data4_loc2', 'Data5_loc1', 'Data5_loc2', 'Data6_loc1', 'Data6_loc2',\n",
    "    'Data7_loc1', 'Data7_loc2', 'Data8_loc1', 'Data8_loc2', 'Data9_loc1', 'Data9_loc2', \n",
    "    'Data10_loc1', 'Data10_loc2', 'Data11_loc1', 'Data11_loc2', 'Data12_loc1', 'Data12_loc2',\n",
    "     'Data13_loc1', 'Data13_loc2',  'Data14_loc1', 'Data14_loc2'], inplace=True)\n",
    "\n",
    "# Convert the consolidated data to a list\n",
    "consolidated_data_list = consolidated_data_both_locations.values.tolist()\n",
    "\n",
    "# Determine the starting row for placing the consolidated data\n",
    "start_row = 20  # Assuming you want to start placing the consolidated data in row 20\n",
    "\n",
    "# Put the consolidated data back into the Excel worksheet\n",
    "for row_index, row_data in enumerate(consolidated_data_list):\n",
    "    for col_index, cell_value in enumerate(row_data):\n",
    "        cell = ws.cell(row=start_row + row_index, column=col_index + 1)\n",
    "        cell.value = cell_value\n",
    "\n",
    "# Save the updated workbook\n",
    "wb.save(\"StaffPerformanceOverviewtest-06-23 test copy.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reportwflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
